{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import glob\n",
    "from scipy.spatial.transform import Rotation\n",
    "import numpy as np\n",
    "import laspy\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "VALID_HEIGHT_ONLY = False\n",
    "CLASSIFY_CATEGORY = False\n",
    "\n",
    "POINT_ATTR = {\n",
    "    'X': 0,\n",
    "    'Y': 1,\n",
    "    'Z': 2,\n",
    "    'INTENSITY': 3,\n",
    "    'GPS': 4,\n",
    "    'INDEX': 5,\n",
    "    'R':6,\n",
    "    'G':7,\n",
    "    'B':8,\n",
    "    'CATEGORY':9\n",
    "}\n",
    "\n",
    "SENSOR_TYPE = {\n",
    "    'CAMERA': 0,\n",
    "    'LIDAR': 1\n",
    "}\n",
    "\n",
    "SENSOR = {\n",
    "    'FC': {'id': 0, 'name':'ring_front_center', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[1125, 1825]},\n",
    "    'FL': {'id': 1, 'name':'ring_front_left', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[825, 1550]},\n",
    "    'FR': {'id': 2, 'name':'ring_front_right', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[825, 1550]},\n",
    "    'RL': {'id': 3, 'name':'ring_rear_left', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[885, 1285]},\n",
    "    'RR': {'id': 4, 'name':'ring_rear_right', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[885, 1285]},\n",
    "    'SL': {'id': 5, 'name':'ring_side_left', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[825, 1550]},\n",
    "    'SR': {'id': 6, 'name':'ring_side_right', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[825, 1550]},\n",
    "    'SFL': {'id': 7, 'name':'stereo_front_left', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[1125, 1825]},\n",
    "    'SFR': {'id': 8, 'name':'stereo_front_right', 'type':SENSOR_TYPE['CAMERA'], 'valid_height':[1125, 1825]},\n",
    "    'UL': {'id': 9, 'name':'up_lidar', 'type':SENSOR_TYPE['LIDAR']},\n",
    "    'DL': {'id': 10, 'name':'down_lidar', 'type':SENSOR_TYPE['LIDAR']},\n",
    "}\n",
    "\n",
    "CATEGORY = {\n",
    "    'NONE': 0,\n",
    "    'REGULAR_VEHICLE': 1,\n",
    "    'PEDESTRIAN': 2,\n",
    "    'BOLLARD': 3,\n",
    "    'CONSTRUCTION_CONE': 3,\n",
    "    'CONSTRUCTION_BARREL': 3,\n",
    "    'STOP_SIGN': 4,\n",
    "    'BICYCLE': 1,\n",
    "    'LARGE_VEHICLE': 1,\n",
    "    'WHEELED_DEVICE': 1,\n",
    "    'BUS': 1,\n",
    "    'BOX_TRUCK': 1,\n",
    "    'SIGN': 5,\n",
    "    'TRUCK': 1,\n",
    "    'MOTORCYCLE': 1,\n",
    "    'BICYCLIST': 2,\n",
    "    'VEHICULAR_TRAILER': 1,\n",
    "    'TRUCK_CAB': 1,\n",
    "    'MOTORCYCLIST': 2,\n",
    "    'DOG': 2,\n",
    "    'SCHOOL_BUS': 1,\n",
    "    'WHEELED_RIDER': 2,\n",
    "    'STROLLER': 1,\n",
    "    'ARTICULATED_BUS': 1,\n",
    "    'MESSAGE_BOARD_TRAILER': 1,\n",
    "    'MOBILE_PEDESTRIAN_SIGN': 5,\n",
    "    'WHEELCHAIR': 1,\n",
    "    'RAILED_VEHICLE': 1,\n",
    "    'OFFICIAL_SIGNALER': 2,\n",
    "    'TRAFFIC_LIGHT_TRAILER': 1,\n",
    "    'ANIMAL': 2\n",
    "}\n",
    "\n",
    "MIN_DISTANCE = 1.0\n",
    "MAX_DISTANCE = 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_timestamp_from_path(path:str)->int:\n",
    "    filename = os.path.basename(path)\n",
    "    return int(filename.split('.')[0])\n",
    "\n",
    "def get_rotation_matrix(w:float, x:float, y:float, z:float)->np.ndarray:\n",
    "    return Rotation([x, y, z, w]).as_matrix()\n",
    "\n",
    "def get_transform_matrix(w:float, x:float, y:float, z:float, tx:float, ty:float, tz:float)->np.ndarray:\n",
    "    mat = np.eye(4)\n",
    "    mat[:3,:3] = get_rotation_matrix(w, x, y, z)\n",
    "    mat[:,3] = [tx, ty, tz, 1.0]\n",
    "    \n",
    "    return mat\n",
    "    \n",
    "def create_points(num_points)->np.ndarray:\n",
    "    return np.zeros((num_points, len(POINT_ATTR)))\n",
    "\n",
    "def transform_points(points:np.ndarray, calibration:np.ndarray):\n",
    "    size = points.shape[0]\n",
    "    coords = np.concatenate((points[:,:3].T, np.ones((1, size))))\n",
    "    coords = np.matmul(calibration, coords)\n",
    "    \n",
    "    return coords[:3,:].T\n",
    "\n",
    "def image_to_numpy(path:str):\n",
    "    image = Image.open(path)\n",
    "    np_image = np.array(image)\n",
    "    \n",
    "    return np_image.transpose(2, 0, 1)\n",
    "\n",
    "# transform points from world to camera pixel\n",
    "def point_to_pixel(points:np.ndarray, to_sensor_calib:np.ndarray, intrinsic:np.ndarray):\n",
    "    coords = transform_points(points, to_sensor_calib)\n",
    "    size = coords.shape[0]\n",
    "    depth = coords[:,2]\n",
    "    \n",
    "    pixel = np.matmul(intrinsic, coords.T)\n",
    "    pixel = pixel / pixel[2, :]\n",
    "\n",
    "    return pixel.T, depth\n",
    "\n",
    "def get_rgb_bilinear(img:np.ndarray, pixel:np.ndarray):\n",
    "    x = pixel[:,0]\n",
    "    y= pixel[:,1]\n",
    "    \n",
    "    x0 = np.floor(x).astype(np.int32)\n",
    "    y0 = np.floor(y).astype(np.int32)\n",
    "    x1 = np.ceil(x).astype(np.int32)\n",
    "    y1 = np.ceil(y).astype(np.int32)\n",
    "\n",
    "    lt = img[:, y0, x0]\n",
    "    lb = img[:, y1, x0]\n",
    "    rt = img[:, y0, x1]\n",
    "    rb = img[:, y1, x1]\n",
    "    \n",
    "    wa = np.expand_dims(((x1.astype(np.float16) - x) * (y1.astype(np.float16) - y)), 0)\n",
    "    wb = np.expand_dims(((x1.astype(np.float16) - x) * (y - y0.astype(np.float16))), 0)\n",
    "    wc = np.expand_dims(((x - x0.astype(np.float16)) * (y1.astype(np.float16) - y)), 0)\n",
    "    wd = np.expand_dims(((x - x0.astype(np.float16)) * (y - y0.astype(np.float16))), 0)\n",
    "    \n",
    "    return (lt * wa + lb * wb + rt * wc + rb * wd).transpose(1, 0)\n",
    "\n",
    "def get_color_from_image(image:str, pixel:np.ndarray, depth:np.ndarray, min_height=1, max_height=0):\n",
    "    np_image = image_to_numpy(image)\n",
    "    _, h, w = np_image.shape\n",
    "    size = pixel.shape[0]\n",
    "    \n",
    "    if min_height > max_height:\n",
    "        max_height = h\n",
    "    \n",
    "    x = pixel[:, 0]\n",
    "    y = pixel[:, 1]\n",
    "    mask = np.ones(size, dtype=bool)\n",
    "    mask = np.logical_and(mask, depth > 0)\n",
    "    mask = np.logical_and(mask, x > 1)\n",
    "    mask = np.logical_and(mask, x < w - 1)\n",
    "    mask = np.logical_and(mask, y > min_height)\n",
    "    mask = np.logical_and(mask, y < max_height - 1)\n",
    "    rgb = get_rgb_bilinear(np_image, pixel[mask,:2])\n",
    "    \n",
    "    return rgb, mask\n",
    "\n",
    "def draw_points_on_image(image:str, pixel:np.ndarray):\n",
    "    np_image = image_to_numpy(image).transpose(1, 2, 0)\n",
    "    x = pixel[:,0]\n",
    "    y = pixel[:,1]\n",
    "    \n",
    "    plt.imshow(np_image)\n",
    "    plt.scatter(x, y, c='blue', marker='x', s=1)\n",
    "    plt.show()\n",
    "    \n",
    "def write_las(path:str, points:np.ndarray):\n",
    "    header = laspy.LasHeader(point_format=3, version=\"1.4\")\n",
    "    header.offsets = np.min(points[:,:3], axis=0)\n",
    "    header.scales = np.array([0.01, 0.01, 0.01])\n",
    "    # header.vlrs\n",
    "    \n",
    "    points_type = points.shape[1]\n",
    "    \n",
    "    las = laspy.LasData(header)\n",
    "    las.x = points[:,0]\n",
    "    las.y = points[:,1]\n",
    "    las.z = points[:,2]\n",
    "    las.intensity = points[:,POINT_ATTR['INTENSITY']]\n",
    "    if points_type >= POINT_ATTR['GPS']:\n",
    "        las.gps_time = points[:,POINT_ATTR['GPS']].astype(np.uint64)\n",
    "    \n",
    "    if points_type >= POINT_ATTR['B']:\n",
    "        las.red = points[:,POINT_ATTR['R']].astype(np.uint8)\n",
    "        las.green = points[:,POINT_ATTR['G']].astype(np.uint8)\n",
    "        las.blue = points[:,POINT_ATTR['B']].astype(np.uint8)\n",
    "    if points_type >= POINT_ATTR['CATEGORY']:\n",
    "        las.classification = points[:,POINT_ATTR['CATEGORY']].astype(np.uint8)\n",
    "    las.write(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EgoPoseParser():\n",
    "    def __init__(self, path:str):\n",
    "        feather = pd.read_feather(path)\n",
    "        \n",
    "        qw = feather['qw']\n",
    "        qx = feather['qx']\n",
    "        qy = feather['qy']\n",
    "        qz = feather['qz']\n",
    "        tx = feather['tx_m']\n",
    "        ty = feather['ty_m']\n",
    "        tz = feather['tz_m']\n",
    "        \n",
    "        self.timestamps = feather['timestamp_ns']\n",
    "        self.ego_calibrations = np.stack(\n",
    "            [get_transform_matrix(qw[i],qx[i],qy[i],qz[i],tx[i],ty[i],tz[i]) for i in range(len(self.timestamps))], axis=0\n",
    "        )\n",
    "    \n",
    "    def get_ego_calibration(self, timestamp: int)->np.ndarray:\n",
    "        return self.ego_calibrations[self.timestamps == timestamp].squeeze()\n",
    "                \n",
    "    \n",
    "class CalibrationParser():\n",
    "    def __init__(self, path:str):\n",
    "        feather = pd.read_feather(path)\n",
    "        \n",
    "        qw = feather['qw']\n",
    "        qx = feather['qx']\n",
    "        qy = feather['qy']\n",
    "        qz = feather['qz']\n",
    "        tx = feather['tx_m']\n",
    "        ty = feather['ty_m']\n",
    "        tz = feather['tz_m']\n",
    "        \n",
    "        self.sensor_calibrations = np.stack(\n",
    "            [get_transform_matrix(qw[i],qx[i],qy[i],qz[i],tx[i],ty[i],tz[i]) for i in range(len(qw))], axis=0\n",
    "        )\n",
    "    \n",
    "    def get(self, sensor_id:int)->np.ndarray:\n",
    "        return self.sensor_calibrations[sensor_id].squeeze()\n",
    "        \n",
    "\n",
    "class IntrinsicParser():\n",
    "    def __init__(self, path:str) -> None:\n",
    "        feather = pd.read_feather(path)\n",
    "        \n",
    "        fx_px = feather['fx_px']\n",
    "        fy_px = feather['fy_px']\n",
    "        cx_px = feather['cx_px']\n",
    "        cy_px = feather['cy_px']\n",
    "        \n",
    "        self.intrinsics = np.stack([np.eye(3) for _ in range(len(fx_px))], axis=0)\n",
    "        self.intrinsics[:, 0, 0] = fx_px\n",
    "        self.intrinsics[:, 1, 1] = fy_px\n",
    "        self.intrinsics[:, 0, 2] = cx_px\n",
    "        self.intrinsics[:, 1, 2] = cy_px\n",
    "    \n",
    "    def get(self, sensor_id:int)->np.ndarray:\n",
    "        return self.intrinsics[sensor_id]\n",
    "\n",
    "\n",
    "class LogMapArchive():\n",
    "    def __init__(self, path) -> None:\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.lane_segments = []\n",
    "        self.pedestrian_crossings = []\n",
    "        \n",
    "        # drivable_area\n",
    "        self.drivable_areas = {}\n",
    "        for id in data['drivable_areas']:\n",
    "            coords = []\n",
    "            for boundary in data['drivable_areas'][id]['area_boundary']:\n",
    "                z = 0 if math.isnan(boundary['z']) else boundary['z']\n",
    "                coords.append(np.array([boundary['x'], boundary['y'], z]))\n",
    "            coords = np.stack(coords, axis=0)\n",
    "            self.drivable_areas[id] = coords\n",
    "            \n",
    "    def get_drivable_areas(self)->str:\n",
    "        keys = []\n",
    "        for key, _ in self.drivable_areas.items():\n",
    "            keys.append(key)\n",
    "        \n",
    "        return keys\n",
    "                \n",
    "    def get_drivable_points(self, id:str)->np.ndarray:\n",
    "        coords = self.drivable_areas[id]\n",
    "        points = create_points(coords.shape[0])\n",
    "        points[:,:3] = coords\n",
    "        points[:,POINT_ATTR['INTENSITY']] = 255\n",
    "        \n",
    "        return points\n",
    "\n",
    "\n",
    "class Annotation():\n",
    "    def __init__(self, category:int, length:float, width:float, height:float, transform_mat:np.ndarray, inner_points:int) -> None:\n",
    "        self.category = category\n",
    "        self.length = length/2 + 5e-2\n",
    "        self.width = width/2 + 5e-2\n",
    "        self.height = height/2 + 5e-2\n",
    "        self.transform_mat = np.linalg.inv(transform_mat)\n",
    "        self.inner_points = inner_points\n",
    "    \n",
    "    def classify_points(self, points:np.ndarray) -> None:\n",
    "        size = points.shape[0]\n",
    "        coords = points[:,:3]\n",
    "        coords = transform_points(coords, self.transform_mat)\n",
    "        \n",
    "        xs = coords[:,0]\n",
    "        ys = coords[:,1]\n",
    "        zs = coords[:,2]\n",
    "        \n",
    "        mask = xs >= -self.length\n",
    "        mask = np.logical_and(mask, xs<=self.length)\n",
    "        mask = np.logical_and(mask, ys>=-self.width)\n",
    "        mask = np.logical_and(mask, ys<=self.width)\n",
    "        mask = np.logical_and(mask, zs>=-self.height)\n",
    "        mask = np.logical_and(mask, zs<=self.height)\n",
    "        \n",
    "        categories = np.zeros((size))\n",
    "        categories[mask] = self.category\n",
    "        \n",
    "        diff = self.inner_points - categories[mask].shape[0]\n",
    "        # if diff > 1:\n",
    "        #     print(self.category, diff)\n",
    "        \n",
    "        return categories\n",
    "        \n",
    "\n",
    "class AnnotationParser():\n",
    "    def __init__(self, path:str) -> None:\n",
    "        feather = pd.read_feather(path)\n",
    "        \n",
    "        timestamps = feather['timestamp_ns']\n",
    "        categories = feather['category']\n",
    "        lengths = feather['length_m']\n",
    "        widths = feather['width_m']\n",
    "        heights = feather['height_m']\n",
    "        qw = feather['qw']\n",
    "        qx = feather['qx']\n",
    "        qy = feather['qy']\n",
    "        qz = feather['qz']\n",
    "        tx = feather['tx_m']\n",
    "        ty = feather['ty_m']\n",
    "        tz = feather['tz_m']\n",
    "        inner_points = feather['num_interior_pts']\n",
    "        \n",
    "        num_data = len(timestamps)\n",
    "        transform_matrix = [get_transform_matrix(qw[i],qx[i],qy[i],qz[i],tx[i],ty[i],tz[i]) for i in range(num_data)]\n",
    "        \n",
    "        self.annotations = {}\n",
    "        for i in range(num_data):\n",
    "            timestamp = timestamps[i]\n",
    "            if not timestamp in self.annotations:\n",
    "                self.annotations[timestamp] = []\n",
    "            self.annotations[timestamp].append(Annotation(CATEGORY[categories[i]], lengths[i], widths[i], heights[i], transform_matrix[i], inner_points[i]))\n",
    "            \n",
    "    def get_annotations(self, timestamp:int)->list[Annotation]:\n",
    "        return self.annotations[timestamp]\n",
    "        \n",
    "\n",
    "\n",
    "class Lidar():\n",
    "    def __init__(self, timestamp:int, path:str, ego_calibration:np.ndarray, ul_calibration:np.ndarray, dl_calibration:np.ndarray, annotations:list[Annotation]):\n",
    "        self.timestamp = timestamp\n",
    "        self.path = path\n",
    "        self.ego_calibration = ego_calibration\n",
    "        self.ul_calibration = ul_calibration\n",
    "        self.dl_calibration = dl_calibration\n",
    "        self.annotations = annotations\n",
    "        self.is_init = False\n",
    "        \n",
    "    def init(self)->None:\n",
    "\n",
    "        feather = pd.read_feather(self.path)\n",
    "        xs = feather['x']\n",
    "        ys = feather['y']\n",
    "        zs = feather['z']\n",
    "\n",
    "        coordinates = np.stack([xs, ys, zs], axis=1)\n",
    "        laser_number = feather['laser_number']\n",
    "        intensities = feather['intensity']\n",
    "        gps_times = feather['offset_ns']\n",
    "        \n",
    "        # # distance filter\n",
    "        # distance = np.sum(np.square(coordinates), axis=1)\n",
    "        # distance_filter = distance <= MAX_DISTANCE**2\n",
    "        # coordinates = coordinates[distance_filter]\n",
    "        # laser_number = laser_number[distance_filter]\n",
    "        # intensities = intensities[distance_filter]\n",
    "        # gps_times = gps_times[distance_filter]\n",
    "        \n",
    "        num_points = coordinates.shape[0]\n",
    "        categories = np.zeros((num_points))\n",
    "        point_index = np.arange(num_points)\n",
    "        \n",
    "        \n",
    "        # transform coordinates from lidar to world\n",
    "        up_index = laser_number[laser_number >= 32]\n",
    "        down_index = laser_number[laser_number < 32]\n",
    "        # lidar to ego vehicle\n",
    "        coordinates[up_index] = transform_points(coordinates[up_index], self.ul_calibration)\n",
    "        coordinates[down_index] = transform_points(coordinates[down_index], self.dl_calibration)\n",
    "        \n",
    "        # classify points with annotations\n",
    "        if CLASSIFY_CATEGORY:\n",
    "            for annotation in self.annotations:\n",
    "                classified = annotation.classify_points(coordinates)\n",
    "                valid = classified > 0\n",
    "                categories[valid] = classified[valid]\n",
    "\n",
    "        # ego vehicle to world\n",
    "        coordinates = transform_points(coordinates, self.ego_calibration)\n",
    "        \n",
    "        self.coordinates = coordinates\n",
    "        self.intensities = intensities\n",
    "        self.gps_times = gps_times + self.timestamp\n",
    "        self.categories = categories\n",
    "        self.point_index = point_index\n",
    "        self.is_init = True\n",
    "    \n",
    "    # x, y, z, intensity, gps_time, point-index\n",
    "    def get_points(self)->np.ndarray:\n",
    "        if not self.is_init:\n",
    "            self.init()\n",
    "        \n",
    "        points = create_points(self.coordinates.shape[0])\n",
    "        points[:,:3] = self.coordinates\n",
    "        points[:,POINT_ATTR['INTENSITY']] = self.intensities\n",
    "        points[:,POINT_ATTR['GPS']] = self.gps_times\n",
    "        points[:,POINT_ATTR['INDEX']] = self.point_index\n",
    "        points[:,POINT_ATTR['CATEGORY']] = self.categories\n",
    "        \n",
    "        return points\n",
    "\n",
    "class Camera():\n",
    "    def __init__(self, timestamp:int, images:list[str], ego_calibration:np.ndarray, sensor_calibrations:CalibrationParser, intrinsics:IntrinsicParser) -> None:\n",
    "        self.timestamp = timestamp\n",
    "        self.images = images\n",
    "        self.ego_calibraion = ego_calibration\n",
    "        self.sensor_calibrations = sensor_calibrations\n",
    "        self.intrinsics = intrinsics\n",
    "        \n",
    "    def paint_points(self, points:np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        painted_points = []\n",
    "        # world to vehicle\n",
    "        coords = transform_points(points, np.linalg.inv(self.ego_calibraion))\n",
    "        \n",
    "        for _, item in SENSOR.items():\n",
    "            sensor_id = item['id']\n",
    "            if sensor_id >= SENSOR['SFL']['id']:\n",
    "                continue\n",
    "\n",
    "            valid_height = item['valid_height'] if VALID_HEIGHT_ONLY else [1, 0]\n",
    "            image = self.images[sensor_id]\n",
    "            cam_calib = self.sensor_calibrations.get(sensor_id)\n",
    "            intrinsic = self.intrinsics.get(sensor_id)\n",
    "            # project points into camera\n",
    "            pixel, depth = point_to_pixel(coords, np.linalg.inv(cam_calib), intrinsic)\n",
    "            rgb, mask = get_color_from_image(image, pixel, depth, valid_height[0], valid_height[1])\n",
    "            points[mask,POINT_ATTR['R']:POINT_ATTR['R']+3] = rgb\n",
    "            \n",
    "            painted_points.append(points[mask])\n",
    "            points = points[np.logical_not(mask)]\n",
    "            coords = coords[np.logical_not(mask)]\n",
    "            \n",
    "            if DEBUG_MODE:\n",
    "                draw_points_on_image(image, pixel[mask])\n",
    "                \n",
    "        points = np.concatenate(painted_points, 0)\n",
    "        \n",
    "        return points\n",
    "    \n",
    "\n",
    "class Argoverse():\n",
    "    def __init__(self, root:str) -> None:\n",
    "        self.root = root\n",
    "        \n",
    "        self.sensor_calibrations = CalibrationParser(join(root, 'calibration', 'egovehicle_SE3_sensor.feather'))\n",
    "        self.intrinsics = IntrinsicParser(join(root, 'calibration', 'intrinsics.feather'))\n",
    "        \n",
    "        annotations = AnnotationParser(join(root, 'annotations.feather'))\n",
    "        ego_poses = EgoPoseParser(join(root, 'city_SE3_egovehicle.feather'))\n",
    "        self.sensors = self.sync_lidar_camera(self.parse_lidars(ego_poses, annotations), self.parse_cameras(ego_poses))\n",
    "        \n",
    "        # parse map\n",
    "        map_files = glob.glob(join(root, 'map', '*'))\n",
    "        for file in map_files:\n",
    "            if 'log_map_archive' in file:\n",
    "                self.log_map_archive = LogMapArchive(file)\n",
    "    \n",
    "    def parse_cameras(self, ego_poses:EgoPoseParser)->list[Camera]:\n",
    "        num_images = 10e4\n",
    "        cameras = []\n",
    "        num_cams = SENSOR['SR']['id'] + 1\n",
    "        image_files = [[] for _ in range(num_cams)]\n",
    "        \n",
    "        # get all jpg from each sensors dir\n",
    "        for _, item in SENSOR.items():\n",
    "            if item['id'] >= num_cams:\n",
    "                continue\n",
    "            image_files[item['id']] = glob.glob(join(self.root, 'sensors', 'cameras', item['name'], '*.jpg'))\n",
    "            num_images = min(num_images, len(image_files[item['id']]))\n",
    " \n",
    "        # create Camera instances\n",
    "        for i in range(num_images):\n",
    "            timestamp = get_timestamp_from_path(image_files[0][i])\n",
    "            ego_calibration = ego_poses.get_ego_calibration(timestamp)\n",
    "            images= []\n",
    "            for j in range(num_cams):\n",
    "                images.append(image_files[j][i])\n",
    "            \n",
    "            cameras.append(Camera(timestamp, images, ego_calibration, self.sensor_calibrations, self.intrinsics))\n",
    "        \n",
    "        return cameras\n",
    "\n",
    "        \n",
    "    def parse_lidars(self, ego_poses:EgoPoseParser, annotations:AnnotationParser)->list[Lidar]:\n",
    "        ul_calibration = self.sensor_calibrations.get([SENSOR['UL']['id']])\n",
    "        dl_calibration = self.sensor_calibrations.get([SENSOR['DL']['id']])\n",
    "        \n",
    "        lidar_files = glob.glob(join(self.root, 'sensors', 'lidar', '*.feather'))\n",
    "        lidars = []\n",
    "        for lidar_file in lidar_files:\n",
    "            timestamp = get_timestamp_from_path(lidar_file)\n",
    "            ego_calibration = ego_poses.get_ego_calibration(timestamp)\n",
    "            lidars.append(Lidar(timestamp, lidar_file, ego_calibration, ul_calibration, dl_calibration, annotations.get_annotations(timestamp)))\n",
    "            \n",
    "        return lidars\n",
    "    \n",
    "    def sync_lidar_camera(self, lidars:list[Lidar], cameras:list[Camera])->list(tuple((Lidar, Camera))):\n",
    "        sensors = []\n",
    "\n",
    "        for lidar in lidars:\n",
    "            timestamp = lidar.timestamp\n",
    "            \n",
    "            for camera in cameras:\n",
    "                if timestamp < camera.timestamp:\n",
    "                    sensors.append((lidar, camera))\n",
    "                    break\n",
    "        \n",
    "        return sensors\n",
    "\n",
    "    \n",
    "    def get_points(self)->np.ndarray:\n",
    "        num_points = 0\n",
    "        points_list = []\n",
    "        \n",
    "        for sensors in self.sensors:\n",
    "            lidar:Lidar = sensors[0]\n",
    "            points = lidar.get_points()\n",
    "            points[:,POINT_ATTR['INDEX']] += num_points\n",
    "            num_points += points[-1,POINT_ATTR['INDEX']]\n",
    "            \n",
    "            camera:Camera = sensors[1]\n",
    "            points = camera.paint_points(points)\n",
    "            points_list.append(points)\n",
    "        \n",
    "        # points = self.log_map_archive.get_drivable_points()\n",
    "        # points[:,POINT_ATTR['CATEGORY']] = 7\n",
    "        # points_list.append(points)\n",
    "        \n",
    "        return np.concatenate(points_list, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/d/argoverse/WDC/389069d7-e6db-3d22-9328-e228c002bf75'\n",
    "argoverse = Argoverse(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = argoverse.log_map_archive.get_drivable_areas()\n",
    "for id in ids:\n",
    "    points = argoverse.log_map_archive.get_drivable_points(id)\n",
    "    points[:,POINT_ATTR['INDEX']] = np.arange(points.shape[0])\n",
    "    points[:,POINT_ATTR['INTENSITY']] = 254\n",
    "    write_las(join(path, f'{id}.las'), points)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_las(join(path, 'test.las'), argoverse.get_points())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py309",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
